{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe304e6-cb09-4308-beb8-02436662444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: Install packages\n",
    "\n",
    "import sys\n",
    "\n",
    "# Equivalent of `python -m pip install <package>`\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a2229b7-835a-4df6-9a22-a3486f5dfce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import statements and warning suppression\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98622cad-bf59-45e2-af61-c1cfe48b1037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Function for data preprocessing\n",
    "\n",
    "def preprocess_data(df):\n",
    "\n",
    "    # Fill missing values with KNNImputer\n",
    "    knn_imputer = KNNImputer(n_neighbors=5)\n",
    "    df[['Age']] = knn_imputer.fit_transform(df[['Age']])\n",
    "    \n",
    "    # Calculate the mode (most frequent value) of the 'Embarked' column\n",
    "    mode_value = df['Embarked'].mode()[0]\n",
    "    \n",
    "    # Use fillna and assign the result back to the 'Embarked' column\n",
    "    df['Embarked'] = df['Embarked'].fillna(mode_value)\n",
    "\n",
    "    # Encode categorical variables\n",
    "    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "    df['Embarked'] = df['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})  \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f82d927-0f7f-4862-aaed-22296d779e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Reading and preprocessing the dataset\n",
    "\n",
    "# Read the dataset\n",
    "url = 'https://raw.githubusercontent.com/kelly-olsson/WouldYouSurviveTheTitanic/main/dataset/train.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Preprocess the data\n",
    "df = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2bc9455-7943-40e0-b3f6-9bd3eebd2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Setting up predictor and target variables\n",
    "\n",
    "# Separate into x and y values\n",
    "predictorVariables = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "X = df[predictorVariables]\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76d50e91-e2ca-449d-94fb-bf91a47f04cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nPredictor variables: ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
      "Predictor Mutual Information Scores: [0.06  0.147 0.03  0.02  0.017 0.132 0.014]\n",
      "[0 1 2 5]\n",
      "['Pclass' 'Sex' 'Age' 'Fare']\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Feature selection code (Run only if selecting features)\n",
    "\n",
    "\n",
    "####### Comment this code if running entire notebook (only run while selecting best features) ########\n",
    "\n",
    "# Scale the data when searching for best features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, columns=predictorVariables)\n",
    "\n",
    "# Use mutual_info_classif for feature selection\n",
    "test = SelectKBest(score_func=mutual_info_classif, k=4)\n",
    "mi_scores = test.fit(X, y)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Best predictor variables were consistently ['Pclass', 'Sex', 'Age', 'Fare']\n",
    "print(\"\\\\nPredictor variables: \" + str(predictorVariables))\n",
    "print(\"Predictor Mutual Information Scores: \" + str(mi_scores.scores_))\n",
    "\n",
    "# Select significant variables using the get_support() function\n",
    "cols = mi_scores.get_support(indices=True)\n",
    "print(cols)\n",
    "features = X.columns[cols]\n",
    "print(features.values)\n",
    "\n",
    "####### End Feature Selection Section ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe974092-a0f0-49c5-89d1-f3e4a0e655d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Feature selection and scaling\n",
    "\n",
    "# Use consistently best features\n",
    "features = ['Pclass', 'Sex', 'Age', 'Fare']\n",
    "\n",
    "# Re-assign X with significant columns only after chi-square test\n",
    "X = df[features]\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Pickle scaler\n",
    "pickle.dump(scaler, open('sc_x.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "883e5523-e781-4b0f-a594-7e0720cfbd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Data splitting\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd2dcd1b-6622-4641-af18-e10996ee46b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search:  {'C': 0.1}\n",
      "Accuracy scores across folds: [0.776 0.791 0.828 0.752 0.782]\n",
      "Mean Accuracy: 0.7858713949051734\n",
      "Standard deviation Accuracy: 0.02489083764691754\n",
      "\n",
      "Precision scores across folds: [0.756 0.712 0.788 0.702 0.745]\n",
      "Mean Precision: 0.7405380022870105\n",
      "Standard deviation Precision: 0.031102684540876918\n",
      "\n",
      "Recall scores across folds: [0.642 0.792 0.774 0.635 0.673]\n",
      "Mean Recall: 0.7030478955007258\n",
      "Standard deviation Recall: 0.06683855493866012\n",
      "\n",
      "F1 scores across folds: [0.694 0.75  0.781 0.667 0.707]\n",
      "Mean F1: 0.7197134611420325\n",
      "Standard deviation F1: 0.040764630801629585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Build logistic regression model and perform cross-validation\n",
    "\n",
    "# Build logistic regression model\n",
    "logisticModel = LogisticRegression(fit_intercept=True, solver='liblinear')\n",
    "grid = GridSearchCV(logisticModel, param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100]}, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Report best parameters as evaluated by grid search\n",
    "print(\"Best parameters found by grid search: \", grid.best_params_)\n",
    "\n",
    "# Identify best model\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Report best model metrics\n",
    "scoring_metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "for metric in scoring_metrics:\n",
    "    scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring=metric)\n",
    "    print(f\"{metric.capitalize()} scores across folds: {scores}\")\n",
    "    print(f\"Mean {metric.capitalize()}: {scores.mean()}\")\n",
    "    print(f\"Standard deviation {metric.capitalize()}: {scores.std()}\\n\")\n",
    "\n",
    "# Pickle trained model\n",
    "with open('model_pkl', 'wb') as files:\n",
    "    pickle.dump(grid.best_estimator_, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edb2b477-ab20-4d07-a0a8-27a49827c85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Predictions\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 1 1 0 1\n",
      " 0 1 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0\n",
      " 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 1 0 0 0 1 1 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0\n",
      " 1 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0\n",
      " 0]\n",
      "\n",
      "Accuracy: 0.8026905829596412\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted    0   1\n",
      "Actual            \n",
      "0          122  22\n",
      "1           22  57\n",
      "Recall: 0.7215189873417721\n",
      "Precision: 0.7215189873417721\n",
      "F1-Score: 0.7215189873417721\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Load best model and make some predictions and score them\n",
    "\n",
    "# Load saved model\n",
    "with open('model_pkl', 'rb') as f:\n",
    "    loadedModel = pickle.load(f)\n",
    "\n",
    "y_pred = loadedModel.predict(X_test)\n",
    "print(\"***Predictions\")\n",
    "print(y_pred)\n",
    "\n",
    "# Show confusion matrix and accuracy scores\n",
    "cm = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print('\\nAccuracy:', accuracy)\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(cm)\n",
    "print(\"Recall: \" + str(recall))\n",
    "print(\"Precision: \" + str(precision))\n",
    "print(\"F1-Score: \" + str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2cb9202-4d4c-463f-821b-40e9d60f0182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single prediction: [0]\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Load best model and make some predictions and score them\n",
    "\n",
    "# Create a single prediction.\n",
    "singleSampleDf = pd.DataFrame(columns=features)\n",
    "\n",
    "# All men who died in train data\n",
    "pClass =  3\n",
    "sex = 0\n",
    "age = 22\n",
    "fare = 7.25\n",
    "\n",
    "passengerData = {'Pclass': pClass, 'Sex': sex, 'Age': age, 'Fare': fare}\n",
    "singleSampleDf = pd.DataFrame([passengerData])\n",
    "\n",
    "# Scale the singleSampleDf using the same scaler object\n",
    "loaded_scalerX = pickle.load(open('sc_x.pkl', 'rb'))\n",
    "singleSampleDf_scaled = loaded_scalerX.transform(singleSampleDf)\n",
    "\n",
    "singlePrediction = loadedModel.predict(singleSampleDf_scaled)\n",
    "print(\"Single prediction: \" + str(singlePrediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
